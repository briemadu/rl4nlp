---
title: Bibliography
layout: default
navigation_weight: 2
---

# Bibliography

A non-exhaustive list of RL+NLP papers. You can choose a paper from this list or suggest other papers.
  
**Coreference resolution**
* CLARK, Kevin; MANNING, Christopher D. Deep Reinforcement Learning for Mention-Ranking Coreference Models. In: Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. 2016. S. 2256-2262. [link](https://www.aclweb.org/anthology/D16-1245/)
  
**Dependency parsing** 
* LÊ, Minh; FOKKENS, Antske. Tackling Error Propagation through Reinforcement Learning: A Case of Greedy Dependency Parsing. In: Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers. 2017. S. 677-687. [link](https://www.aclweb.org/anthology/E17-1064/)
* ZHANG, Lidan; CHAN, Kwok Ping. Dependency parsing with energy-based reinforcement learning. In: Proceedings of the 11th International Conference on Parsing Technologies. Association for Computational Linguistics, 2009. S. 234-237. [link](https://www.aclweb.org/anthology/W09-3838/)
  
**Dialog**
* ENGLISH, Michael S.; HEEMAN, Peter A. Learning mixed initiative dialog strategies by using reinforcement learning on both conversants. In: Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2005. S. 1011-1018. [link](https://dl.acm.org/doi/10.3115/1220575.1220702)
* FANG, Meng; LI, Yuan; COHN, Trevor. Learning how to Active Learn: A Deep Reinforcement Learning Approach. In: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 2017. S. 595-605. [link](https://www.aclweb.org/anthology/D17-1063/)
* PAEK, Tim. Reinforcement learning for spoken dialogue systems: Comparing strengths and weaknesses for practical deployment. In: Proc. Dialog-on-Dialog Workshop, Interspeech. 2006. [link](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.94.4229&rep=rep1&type=pdf)
* PAPANGELIS, Alexandros. A Comparative Study of Reinforcement Learning Techniques on Dialogue Management. In: Proceedings of the Student Research Workshop at the 13th Conference of the European Chapter of the Association for Computational Linguistics. 2012. S. 22-31. [link](https://www.aclweb.org/anthology/E12-3003/)
* SINGH, Satinder P., et al. Reinforcement learning for spoken dialogue systems. In: Advances in Neural Information Processing Systems. 2000. S. 956-962. [link](http://papers.nips.cc/paper/1775-reinforcement-learning-for-spoken-dialogue-systems.pdf)
  
**Grammatical error correction**
* SAKAGUCHI, Keisuke; POST, Matt; VAN DURME, Benjamin. Grammatical Error Correction with Neural Reinforcement Learning. In: Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers). 2017. S. 366-372. [link](https://www.aclweb.org/anthology/I17-2062/)
  
**Human-robot interaction**
* CRUZ, Francisco, et al. Interactive reinforcement learning through speech guidance in a domestic scenario. In: 2015 International Joint Conference on Neural Networks (IJCNN). IEEE, 2015. S. 1-8. [link](https://ieeexplore.ieee.org/abstract/document/7280477)
  
**Image Captioning**
* RENNIE, Steven J., et al. Self-critical sequence training for image captioning. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017. S. 7008-7024. [link](http://openaccess.thecvf.com/content_cvpr_2017/html/Rennie_Self-Critical_Sequence_Training_CVPR_2017_paper.html)
  
**Information Extraction**
* NARASIMHAN, Karthik; YALA, Adam; BARZILAY, Regina. Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning. In: Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. 2016. S. 2355-2365. [link](https://www.aclweb.org/anthology/D16-1261/)
* TANIGUCHI, Motoki; MIURA, Yasuhide; OHKUMA, Tomoko. Joint Modeling for Query Expansion and Information Extraction with Reinforcement Learning. In: Proceedings of the First Workshop on Fact Extraction and VERification (FEVER). 2018. S. 34-39. [link](https://www.aclweb.org/anthology/W18-5506/)
  
**Instructions**
* BRANAVAN, Satchuthananthavale RK, et al. Reinforcement learning for mapping instructions to actions. In: Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1-Volume 1. Association for Computational Linguistics, 2009. S. 82-90. [link](https://dl.acm.org/doi/10.5555/1687878.1687892)
  
**Knowledge graph reasoning**
* XIONG, Wenhan; HOANG, Thien; WANG, William Yang. DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning. In: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 2017. S. 564-573. [link](https://www.aclweb.org/anthology/D17-1060/)
  
**Language model**
* RANZATO, Marc'Aurelio, et al. Sequence level training with recurrent neural networks. arXiv preprint arXiv:1511.06732, 2015. [link](https://arxiv.org/abs/1511.06732)
  
**Machine Translation**
* GRISSOM II, Alvin, et al. Don’t until the final verb wait: Reinforcement learning for simultaneous machine translation. In: Proceedings of the 2014 Conference on empirical methods in natural language processing (EMNLP). 2014. S. 1342-1352. [link](https://www.aclweb.org/anthology/D14-1140/)
* WU, Lijun, et al. A Study of Reinforcement Learning for Neural Machine Translation. In: Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. 2018. S. 3612-3621. [link](https://www.aclweb.org/anthology/D18-1397/)
  
**Math word problem**
* HUANG, Danqing, et al. Neural math word problem solver with reinforcement learning. In: Proceedings of the 27th International Conference on Computational Linguistics. 2018. S. 213-223. [link](https://www.aclweb.org/anthology/C18-1018/)
  
**Relation Extraction**
* ZENG, Xiangrong, et al. Large scaled relation extraction with reinforcement learning. In: Thirty-Second AAAI Conference on Artificial Intelligence. 2018. [link](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/16257)
  
**Semantic Parsing**
* GUU, Kelvin, et al. From Language to Programs: Bridging Reinforcement Learning and Maximum Marginal Likelihood. In: Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2017. S. 1051-1062. [link](https://www.aclweb.org/anthology/P17-1097/)
  
**Taxonomy induction**
* MAO, Yuning, et al. End-to-End Reinforcement Learning for Automatic Taxonomy Induction. In: Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2018. S. 2462-2472. [link](https://www.aclweb.org/anthology/P18-1229/)
  
**Text-based games**
  
**Text classification**
* ZHANG, Tianyang; HUANG, Minlie; ZHAO, Li. Learning structured representation for text classification via reinforcement learning. In: Thirty-Second AAAI Conference on Artificial Intelligence. 2018. [link](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/16537)

**Text summarization**
* LEE, Gyoung Ho; LEE, Kong Joo. Automatic text summarization using reinforcement learning with embedding features. In: Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers). 2017. S. 193-197. [link](https://www.aclweb.org/anthology/I17-2033/)
* PAULUS, Romain; XIONG, Caiming; SOCHER, Richard. A deep reinforced model for abstractive summarization. arXiv preprint arXiv:1705.04304, 2017.[link](https://arxiv.org/abs/1705.04304)
  
**Video captioning**
* WANG, Xin, et al. Video captioning via hierarchical reinforcement learning. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018. S. 4213-4222. [link](http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_Video_Captioning_via_CVPR_2018_paper.html)
